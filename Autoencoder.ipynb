{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Imports and Determine Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Define Imports and Determine Device\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "os.sys.path.insert(0, \"source\")\n",
    "from DiabetesData import DiabeticData\n",
    "from Autoencoder import ConvAutoencoder\n",
    "from ConvVarAutoencoder import ConvVAE\n",
    "from DogCatData import DogCatData\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "datatype=\"dogcat\"\n",
    "batch_size=16\n",
    "epochs = 5\n",
    "model_file = \"\"\n",
    "normalize=False\n",
    "size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'dog': 11274})\n",
      "Counter({'cat': 1514, 'dog': 614})\n",
      "Counter({'cat': 1516, 'dog': 612})\n",
      "       Unnamed: 0       filename  label text_label\n",
      "0           11301    dog.892.jpg      0        dog\n",
      "1            8981   dog.6831.jpg      0        dog\n",
      "2           10970   dog.8621.jpg      0        dog\n",
      "3            8608   dog.6496.jpg      0        dog\n",
      "4            7027   dog.5072.jpg      0        dog\n",
      "...           ...            ...    ...        ...\n",
      "11269        7981   dog.5931.jpg      0        dog\n",
      "11270        9460   dog.7262.jpg      0        dog\n",
      "11271        1604  dog.11440.jpg      0        dog\n",
      "11272        8762   dog.6634.jpg      0        dog\n",
      "11273        3741   dog.2114.jpg      0        dog\n",
      "\n",
      "[11274 rows x 4 columns]\n",
      "      Unnamed: 0       filename  label text_label\n",
      "0          15337   cat.1300.jpg      1        cat\n",
      "1          14916  cat.12171.jpg      1        cat\n",
      "2          15181   cat.1241.jpg      1        cat\n",
      "3          12769  cat.10239.jpg      1        cat\n",
      "4          14544  cat.11837.jpg      1        cat\n",
      "...          ...            ...    ...        ...\n",
      "2123       13494  cat.10892.jpg      1        cat\n",
      "2124       13625  cat.11009.jpg      1        cat\n",
      "2125       14755  cat.12026.jpg      1        cat\n",
      "2126       14622  cat.11907.jpg      1        cat\n",
      "2127       13589  cat.10978.jpg      1        cat\n",
      "\n",
      "[2128 rows x 4 columns]\n",
      "      Unnamed: 0       filename  label text_label\n",
      "0          13464  cat.10865.jpg      1        cat\n",
      "1           3093   dog.1531.jpg      0        dog\n",
      "2           7538   dog.5532.jpg      0        dog\n",
      "3          12976  cat.10425.jpg      1        cat\n",
      "4          12374   dog.9886.jpg      0        dog\n",
      "...          ...            ...    ...        ...\n",
      "2123       13783  cat.11151.jpg      1        cat\n",
      "2124       12742  cat.10214.jpg      1        cat\n",
      "2125        8228   dog.6153.jpg      0        dog\n",
      "2126       14085  cat.11423.jpg      1        cat\n",
      "2127       13726   cat.1110.jpg      1        cat\n",
      "\n",
      "[2128 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if datatype == \"diabetes\":\n",
    "    filename = \"data/trainLabels_ad.csv\"\n",
    "    root_dir = \"data/diabetes_resized\"\n",
    "    task = ([0],[4])\n",
    "    # task = ([0,1,2], [3,4])\n",
    "    # task = ([0,1,2], (3,4))\n",
    "    classes = [\"none\", \"proliferative\"]\n",
    "    train = pd.read_csv(\"data/diabetes_ad_train.csv\")\n",
    "    val = pd.read_csv(\"data/diabetes_ad_valid.csv\")\n",
    "    test = pd.read_csv(\"data/diabetes_ad_test.csv\")\n",
    "\n",
    "    print(Counter(train['level']))\n",
    "    print(Counter(val['level']))\n",
    "    print(Counter(test['level']))\n",
    "    data = {'train': DiabeticData(df = train, transform_key=\"train\", root_dir=root_dir, task = task, normalize = normalize),\n",
    "            'valid': DiabeticData(df = val, transform_key=\"valid\", root_dir=root_dir, task = task, normalize = normalize),\n",
    "            'test': DiabeticData(df = test, transform_key=\"test\", root_dir=root_dir, task = task, normalize = normalize)\n",
    "            }\n",
    "\n",
    "\n",
    "elif datatype == \"dogcat\":\n",
    "    filename = \"data/dogcat_ad.csv\"\n",
    "    root_dir = \"data/dogcat/train\"\n",
    "    classes = ['dog', 'cat']\n",
    "    # task = ([0,1,2], (3,4))\n",
    "\n",
    "    train = pd.read_csv(\"data/dogcat_ad_train.csv\")\n",
    "    val = pd.read_csv(\"data/dogcat_ad_valid.csv\")\n",
    "    test = pd.read_csv(\"data/dogcat_ad_test.csv\")\n",
    "    print(Counter(train['text_label']))\n",
    "    print(Counter(val['text_label']))\n",
    "    print(Counter(test['text_label']))\n",
    "    data = {'train': DogCatData(df = train, transform_key=\"train\", root_dir=root_dir, normalize = normalize),\n",
    "            'valid': DogCatData(df = val, transform_key=\"valid\", root_dir=root_dir, normalize = normalize),\n",
    "            'test': DogCatData(df = test, transform_key=\"test\", root_dir=root_dir, normalize = normalize)\n",
    "            }\n",
    "\n",
    "dataloaders = {\n",
    "        'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "        'valid': DataLoader(data['valid'], batch_size=batch_size, shuffle=True),\n",
    "        'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/705 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvAutoencoder(\n",
      "  (conv1): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(512, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (t_conv1): ConvTranspose2d(4, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (t_conv2): ConvTranspose2d(512, 3, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (criterion): MSELoss()\n",
      ")\n",
      "in fit function\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tntech.edu/kebrown46/miniconda3/envs/xai/lib/python3.7/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 705/705 [01:44<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.186512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/705 [00:00<01:38,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [01:43<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 \tTraining Loss: 0.145050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/705 [00:00<01:42,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [01:43<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 \tTraining Loss: 0.142146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/705 [00:00<01:39,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 550/705 [01:20<00:23,  6.72it/s]"
     ]
    }
   ],
   "source": [
    "model = ConvAutoencoder(device, datatype)\n",
    "print(model)\n",
    "if model_file != \"\":\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "model.fit(epochs, dataloaders[\"train\"], dataloaders[\"valid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(dataloaders[\"test\"])\n",
    "images, labels = dataiter.next()\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images.to(device))\n",
    "# output = F.softmax(output)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(batch_size, 3, size, size)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.cpu().detach().numpy()\n",
    "\n",
    "# # plot the first ten input images and then reconstructed images\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "\n",
    "# # input images on top row, reconstructions on bottom\n",
    "# for images, row in zip([images, output], axes):\n",
    "#     for img, ax in zip(images, row):\n",
    "#         ax.imshow(np.squeeze(img))\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(output[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we loop through the training set and calculate reconstruction loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders['valid'] = DataLoader(data['valid'], batch_size=1, shuffle=True)\n",
    "dataloaders['test'] = DataLoader(data['test'], batch_size=1, shuffle=True)\n",
    "\n",
    "results = []\n",
    "results_cols = [\"Image Label\", \"Reconstruction Loss\"]\n",
    "for x, y in dataloaders['valid']:\n",
    "    X = x.to(device)\n",
    "    output = model(X)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    for i in range(y.shape[0]):\n",
    "        ls = 0\n",
    "        image = x[i].numpy()\n",
    "        ouptut = output[i]\n",
    "        label = y[i].numpy()\n",
    "        ls = np.sum(np.square(image.ravel() - output.ravel()))\n",
    "        # ls = model.criterion(output, image)\n",
    "        results.append([label, ls])\n",
    "\n",
    "results = pd.DataFrame(results, columns=results_cols)\n",
    "results.to_csv(\"reconstruction_error.csv\")\n",
    "\n",
    "\n",
    "#find error threshold on validation set\n",
    "\n",
    "\n",
    "\n",
    "#evaluate on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "label_1 = results[results[\"Image Label\"] == 1]\n",
    "label_0 = results[results[\"Image Label\"] == 0]\n",
    "print(label_0)\n",
    "print(label_1)\n",
    "avg_1 = np.mean(label_1['Reconstruction Loss'].values)\n",
    "avg_0 = np.mean(label_0['Reconstruction Loss'].values)\n",
    "\n",
    "print(\"Average Reconstruction Error (Prediction = 0)\", avg_0)\n",
    "print(\"Average Reconstruction Error (Prediction = 1)\", avg_1)\n",
    "\n",
    "plt.hist(label_1['Reconstruction Loss'].values, density=False, bins=30, color='blue')\n",
    "plt.hist(label_0['Reconstruction Loss'].values, density=False, bins=30, alpha = 0.5,color='yellow')\n",
    "plt.xlabel('MSE')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for x, y in dataloaders['test']:\n",
    "    X = x.to(device)\n",
    "    output = model(X)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    for i in range(y.shape[0]):\n",
    "        ls = 0\n",
    "        image = x[i].numpy()\n",
    "        ouptut = output[i]\n",
    "        label = y[i].numpy()\n",
    "        ls = np.sum(np.square(image.ravel() - output.ravel()))\n",
    "        print(\"Label: {0}\\tReconstruction Loss: {1}\\tPrediction: {2}\".format(label,ls,int(ls >= threshold)))\n",
    "        y_true.append(label)\n",
    "        if ls >= threshold:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", rec)\n",
    "print(\"F1-Score: \", f1)\n",
    "print(\"Confusion Matrix: \", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
