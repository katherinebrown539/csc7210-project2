{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Imports and Determine Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ## Define Imports and Determine Device\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "os.sys.path.insert(0, \"source\")\n",
    "from DiabetesData import DiabeticData\n",
    "from Autoencoder import ConvAutoencoder\n",
    "from VGGAutoencoder import VGGAutoencoder\n",
    "from ConvVarAutoencoder import ConvVAE\n",
    "from DogCatData import DogCatData\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "datatype=\"diabetes\"\n",
    "batch_size=16\n",
    "epochs = 30\n",
    "model_file = \"\"\n",
    "normalize=False\n",
    "size=96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 23226})\n",
      "Counter({0: 1305, 4: 341})\n",
      "Counter({0: 1279, 4: 367})\n",
      "       Unnamed: 0  Unnamed: 0.1             image  level\n",
      "0           23248         31705  40036_right.jpeg      0\n",
      "1            3849          5240    6586_left.jpeg      0\n",
      "2           10544         14464   18147_left.jpeg      0\n",
      "3           16706         22819  28799_right.jpeg      0\n",
      "4           11499         15746   19729_left.jpeg      0\n",
      "...           ...           ...               ...    ...\n",
      "23221       18453         25200   31916_left.jpeg      0\n",
      "23222        9982         13702   17191_left.jpeg      0\n",
      "23223       24683         33618   42467_left.jpeg      0\n",
      "23224       10118         13887  17425_right.jpeg      0\n",
      "23225       24112         32878   41528_left.jpeg      0\n",
      "\n",
      "[23226 rows x 4 columns]\n",
      "task = ([0], [4])\n",
      "      Unnamed: 0  Unnamed: 0.1             image  level\n",
      "0          21865         29832   37726_left.jpeg      0\n",
      "1          14013         19225  24247_right.jpeg      0\n",
      "2          18102         24690   31200_left.jpeg      0\n",
      "3          13011         17851  22488_right.jpeg      0\n",
      "4          15073         20641  26011_right.jpeg      0\n",
      "...          ...           ...               ...    ...\n",
      "1641       23011         31393  39660_right.jpeg      0\n",
      "1642       18954         25913  32793_right.jpeg      0\n",
      "1643        2326          3107   3851_right.jpeg      0\n",
      "1644       17352         23677  29915_right.jpeg      0\n",
      "1645       19674         26853  33966_right.jpeg      0\n",
      "\n",
      "[1646 rows x 4 columns]\n",
      "task = ([0], [4])\n",
      "      Unnamed: 0  Unnamed: 0.1             image  level\n",
      "0          10208         14015  17606_right.jpeg      0\n",
      "1          17447         23806   30070_left.jpeg      0\n",
      "2          17079         23303  29475_right.jpeg      0\n",
      "3           8458         11630   14609_left.jpeg      0\n",
      "4           1692          2250    2796_left.jpeg      0\n",
      "...          ...           ...               ...    ...\n",
      "1641       23628         32220   40703_left.jpeg      0\n",
      "1642       23177         31606   39912_left.jpeg      0\n",
      "1643       24591         33493  42308_right.jpeg      0\n",
      "1644        8742         12002   15051_left.jpeg      0\n",
      "1645       26425         30301  38325_right.jpeg      4\n",
      "\n",
      "[1646 rows x 4 columns]\n",
      "task = ([0], [4])\n"
     ]
    }
   ],
   "source": [
    "if datatype == \"diabetes\":\n",
    "    filename = \"data/trainLabels_ad.csv\"\n",
    "    root_dir = \"data/diabetes_resized\"\n",
    "    task = ([0],[4])\n",
    "    # task = ([0,1,2], [3,4])\n",
    "    # task = ([0,1,2], (3,4))\n",
    "    classes = [\"none\", \"proliferative\"]\n",
    "    train = pd.read_csv(\"data/diabetes_ad_train.csv\")\n",
    "    val = pd.read_csv(\"data/diabetes_ad_valid.csv\")\n",
    "    test = pd.read_csv(\"data/diabetes_ad_test.csv\")\n",
    "\n",
    "    print(Counter(train['level']))\n",
    "    print(Counter(val['level']))\n",
    "    print(Counter(test['level']))\n",
    "    data = {'train': DiabeticData(df = train, transform_key=\"train\", root_dir=root_dir, task = task, normalize = normalize),\n",
    "            'valid': DiabeticData(df = val, transform_key=\"valid\", root_dir=root_dir, task = task, normalize = normalize),\n",
    "            'test': DiabeticData(df = test, transform_key=\"test\", root_dir=root_dir, task = task, normalize = normalize)\n",
    "            }\n",
    "\n",
    "\n",
    "elif datatype == \"dogcat\":\n",
    "    filename = \"data/dogcat_ad.csv\"\n",
    "    root_dir = \"data/dogcat/train\"\n",
    "    classes = ['dog', 'cat']\n",
    "    # task = ([0,1,2], (3,4))\n",
    "\n",
    "    train = pd.read_csv(\"data/dogcat_ad_train.csv\")\n",
    "    val = pd.read_csv(\"data/dogcat_ad_valid.csv\")\n",
    "    test = pd.read_csv(\"data/dogcat_ad_test.csv\")\n",
    "    print(Counter(train['text_label']))\n",
    "    print(Counter(val['text_label']))\n",
    "    print(Counter(test['text_label']))\n",
    "    data = {'train': DogCatData(df = train, transform_key=\"train\", root_dir=root_dir, normalize = normalize),\n",
    "            'valid': DogCatData(df = val, transform_key=\"valid\", root_dir=root_dir, normalize = normalize),\n",
    "            'test': DogCatData(df = test, transform_key=\"test\", root_dir=root_dir, normalize = normalize)\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "elif datatype == \"fruit\":\n",
    "    classes = [\"apple\", \"banana\"]\n",
    "    root_dir=\"data/Fruit-Images-Dataset-master\"\n",
    "    train = pd.read_csv(\"data/fruit_ad_train.csv\")\n",
    "    val = pd.read_csv(\"data/fruit_ad_valid.csv\")\n",
    "    test = pd.read_csv(\"data/fruit_ad_test.csv\")\n",
    "    print(Counter(train['text_label']))\n",
    "    print(Counter(val['text_label']))\n",
    "    print(Counter(test['text_label']))\n",
    "    data = {'train': DogCatData(df = train, transform_key=\"train\", root_dir=root_dir, normalize = normalize),\n",
    "            'valid': DogCatData(df = val, transform_key=\"valid\", root_dir=root_dir, normalize = normalize),\n",
    "            'test': DogCatData(df = test, transform_key=\"test\", root_dir=root_dir, normalize = normalize)\n",
    "            }\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'valid': DataLoader(data['valid'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1452 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGAutoencoder(\n",
      "  (enc): VGGEncoder(\n",
      "    (conv_layers): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (16): ReLU()\n",
      "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU()\n",
      "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (22): ReLU()\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (26): ReLU()\n",
      "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): ReLU()\n",
      "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (32): ReLU()\n",
      "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (36): ReLU()\n",
      "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (39): ReLU()\n",
      "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (42): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (dec): Decoder(\n",
      "    (upconv1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (upconv2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (upconv3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (upconv4): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): LeakyReLU(negative_slope=0.2)\n",
      "    (op): Sigmoid()\n",
      "  )\n",
      "  (criterion): MSELoss()\n",
      ")\n",
      "in fit function\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1452/1452 [03:42<00:00,  6.53it/s]\n",
      "  0%|          | 1/1452 [00:00<03:43,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.20125132904210982\tValidation Loss: 6.561248358339071\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 96/1452 [00:14<03:28,  6.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ee434fa1bcbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/csc7210-project2/source/VGGAutoencoder.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epochs, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0;31m# perform a single optimization step (parameter update)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                     \u001b[0;31m# update running training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m#                     print(\"Loss: \" , loss.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xai/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VGGAutoencoder(device=device, task=datatype)\n",
    "# model = ConvAutoencoder(device=device, task=datatype)\n",
    "# model = ConvVAE(4, device=device, task=datatype)\n",
    "print(model)\n",
    "if model_file != \"\":\n",
    "    model.load_state_dict(torch.load(model_file, map_location=torch.device('cpu')))\n",
    "\n",
    "model.fit(epochs, dataloaders[\"train\"], dataloaders[\"valid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# obtain one batch of test images\n",
    "dataiter = iter(dataloaders[\"test\"])\n",
    "images, labels = dataiter.next()\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# get sample outputs\n",
    "output = model(images.to(device))\n",
    "# output = F.softmax(output)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(batch_size, 3, size, size)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.cpu().detach().numpy()\n",
    "\n",
    "# # plot the first ten input images and then reconstructed images\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "\n",
    "# # input images on top row, reconstructions on bottom\n",
    "# for images, row in zip([images, output], axes):\n",
    "#     for img, ax in zip(images, row):\n",
    "#         ax.imshow(np.squeeze(img))\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(output[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(24,4))\n",
    "for idx in np.arange(batch_size):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we loop through the training set and calculate reconstruction loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders['valid'] = DataLoader(data['valid'], batch_size=1, shuffle=True)\n",
    "dataloaders['test'] = DataLoader(data['test'], batch_size=1, shuffle=True)\n",
    "\n",
    "results = []\n",
    "results_cols = [\"Image Label\", \"Reconstruction Loss\"]\n",
    "for x, y in dataloaders['valid']:\n",
    "    X = x.to(device)\n",
    "    output = model(X)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    for i in range(y.shape[0]):\n",
    "        ls = 0\n",
    "        image = x[i].numpy()\n",
    "        ouptut = output[i]\n",
    "        label = y[i].numpy()\n",
    "        ls = np.sum(np.square(image.ravel() - output.ravel()))\n",
    "        # ls = model.criterion(output, image)\n",
    "        results.append([label, ls])\n",
    "\n",
    "results = pd.DataFrame(results, columns=results_cols)\n",
    "results.to_csv(\"reconstruction_error.csv\")\n",
    "\n",
    "\n",
    "#find error threshold on validation set\n",
    "\n",
    "\n",
    "\n",
    "#evaluate on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "label_1 = results[results[\"Image Label\"] == 1]\n",
    "label_0 = results[results[\"Image Label\"] == 0]\n",
    "print(label_0)\n",
    "print(label_1)\n",
    "avg_1 = np.mean(label_1['Reconstruction Loss'].values)\n",
    "avg_0 = np.mean(label_0['Reconstruction Loss'].values)\n",
    "\n",
    "print(\"Average Reconstruction Error (Prediction = 0)\", avg_0)\n",
    "print(\"Average Reconstruction Error (Prediction = 1)\", avg_1)\n",
    "\n",
    "plt.hist(label_1['Reconstruction Loss'].values, density=False, bins=30, color='blue')\n",
    "plt.hist(label_0['Reconstruction Loss'].values, density=False, bins=30, alpha = 0.5,color='yellow')\n",
    "plt.xlabel('MSE')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1500\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for x, y in dataloaders['test']:\n",
    "    X = x.to(device)\n",
    "    output = model(X)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    for i in range(y.shape[0]):\n",
    "        ls = 0\n",
    "        image = x[i].numpy()\n",
    "        ouptut = output[i]\n",
    "        label = y[i].numpy()\n",
    "        ls = np.sum(np.square(image.ravel() - output.ravel()))\n",
    "        print(\"Label: {0}\\tReconstruction Loss: {1}\\tPrediction: {2}\".format(label,ls,int(ls >= threshold)))\n",
    "        y_true.append(label)\n",
    "        if ls >= threshold:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred)\n",
    "rec = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", prec)\n",
    "print(\"Recall: \", rec)\n",
    "print(\"F1-Score: \", f1)\n",
    "print(\"Confusion Matrix: \", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
